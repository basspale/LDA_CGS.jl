{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Recompiling stale cache file /Users/yanagi/.julia/compiled/v1.0/LDA_CGS/FbSPT.ji for LDA_CGS [8b03fa0e-3994-11e9-179b-21593925b643]\n",
      "└ @ Base loading.jl:1190\n"
     ]
    }
   ],
   "source": [
    "#using Pkg\n",
    "#using HDF5\n",
    "using LDA_CGS\n",
    "using JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = []\n",
    "texts = []\n",
    "\n",
    "open(\"./data/hep-ph.json\", \"r\") do f\n",
    "    i=1\n",
    "    for line in eachline(f)\n",
    "        jdict = JSON.parse(line)\n",
    "        words = split(jdict[\"summary\"],r\" | |\\.|\\,|\\n|\\$\")\n",
    "        push!(texts, words)\n",
    "        union!(vocab, collect(words))\n",
    "        i += 1\n",
    "    end\n",
    "end\n",
    "\n",
    "vocab_size,  = size(vocab)\n",
    "word_to_id = Dict()\n",
    "id_to_word = Dict()\n",
    "for i in 1:vocab_size\n",
    "    word_to_id[vocab[i]] = i\n",
    "    id_to_word[i] = vocab[i]\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First make whole corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_size, = size(texts)\n",
    "corpus = []\n",
    "for text in texts\n",
    "    words_id = map(w->word_to_id[w], text)\n",
    "    \n",
    "    counts_d = Dict{Int, Int}()\n",
    "    for iv in words_id\n",
    "        counts_d[iv] = get(counts_d, iv, 0) + 1\n",
    "    end\n",
    "\n",
    "    counts_d_tuple = []\n",
    "    for (key, ct) in counts_d\n",
    "        push!(counts_d_tuple, (key, ct))\n",
    "    end\n",
    "    push!(corpus, counts_d_tuple)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then devide it into corpus for training and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# devide test and train\n",
    "train_ratio = 0.8\n",
    "train_corpus = []\n",
    "test_corpus = []\n",
    "\n",
    "for d in corpus\n",
    "    Nd, = size(d)\n",
    "    length = Int(round(Nd*0.8))\n",
    "    push!(train_corpus, d[1:length])\n",
    "    push!(test_corpus, d[length+1:end])\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First make LDA object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LDA(20, 13182, 561156, #undef, #undef, #undef, #undef, #undef, #undef, #undef, #undef, 6.0e-323, 6.4e-323, 7.0e-323, #undef, 25, 1.33e-322, #undef, #undef, #undef)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K = 20\n",
    "V = vocab_size\n",
    "x = LDA(K, V)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Burn-in (period=10)...\n",
      "epoch=1\n",
      "epoch=2\n",
      "epoch=3\n",
      "epoch=4\n",
      "epoch=5\n",
      "epoch=6\n",
      "epoch=7\n",
      "epoch=8\n",
      "epoch=9\n",
      "epoch=10\n",
      "Sampling from the posterior...\n",
      "epoch=1, PPL=47.90106467790846\n",
      "epoch=2, PPL=47.457031128907396\n"
     ]
    }
   ],
   "source": [
    "burnin = 10\n",
    "sample = 2\n",
    "run_LDA(x, train_corpus, test_corpus, burnin, sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000×20 Array{Float64,2}:\n",
       "  2.0   7.5   0.0   0.0  16.0   0.5  …  0.5   0.5   0.0   4.5   7.5  16.5\n",
       " 26.0   3.0   2.0   0.0  20.5   0.0     0.0   6.0   4.5   4.5   4.0   2.0\n",
       "  0.0   1.0   0.0   4.5  50.5   2.5     0.5  12.5   0.0  13.0   4.0   0.5\n",
       "  2.5   8.0   1.5   6.0  20.5   3.0     8.0  15.5   2.5   1.0   9.0   0.0\n",
       "  0.0   1.0   0.5   6.0   1.5   1.0     7.0  15.0   3.5   0.0  41.5   1.5\n",
       " 12.0   0.5   0.5  12.0   6.5   2.5  …  0.0  14.0   8.0   2.5   5.5   2.5\n",
       "  5.5  26.0   5.5   3.0   0.5   0.5     0.0   2.0   3.0  59.5   1.0   2.0\n",
       "  3.0   2.5   3.0   1.0   0.0   2.0     0.0   1.0  34.0   0.0   5.5   3.5\n",
       "  0.0   5.5   2.5   0.0   3.0   5.5     0.0   1.5   3.0   0.0  11.0   5.5\n",
       "  0.0   4.0   1.5   0.0  18.5   1.5     1.0  25.0   0.5   9.5  42.0   3.5\n",
       "  0.0  13.0   6.5   4.0   6.5  10.0  …  1.5   9.0   1.0   0.5  21.5   0.0\n",
       "  3.5   0.5   1.5  15.0   0.0   0.0     2.0  28.5   0.0   0.0   1.5   0.5\n",
       " 26.5   7.0   0.0   1.0  10.5   0.0     0.0   0.0   1.0  11.5   7.5   2.0\n",
       "  ⋮                             ⋮    ⋱        ⋮                          \n",
       "  1.0   2.5   3.0   4.5   1.0   6.5     1.0   7.0   0.5   0.5   6.0   0.5\n",
       "  0.0   3.5  12.5   0.0   1.0   0.0     0.0   8.5  11.0   0.0   6.5   0.5\n",
       " 23.0  12.5   1.0   0.0   2.5   0.0  …  0.0   0.0   2.0  16.0   9.0   0.0\n",
       "  0.5  25.5   0.0   0.0  10.5   1.5     0.5   0.5   0.0   1.5   2.5   0.5\n",
       "  0.5  10.5   0.5   7.0   1.5   0.0     0.5   3.5   0.5   0.0   9.5   0.0\n",
       "  0.0   1.0   4.0   0.0   8.0  23.0     0.0  21.5   5.0   0.0   1.0   2.0\n",
       "  4.5  10.5   0.5   0.5   1.5   0.0     3.0   6.0   0.0   0.5  11.0   5.5\n",
       "  8.0   1.5   1.0   0.5   0.0   1.0  …  0.0  14.0   0.5   0.0  10.5   0.5\n",
       "  2.0   3.0   6.5   1.0  15.0   0.5     0.0   4.5   0.0   0.0   6.0   5.0\n",
       "  3.0  16.0   5.0   6.0  20.0   0.0     0.0   9.5   0.5   0.0  11.0   3.5\n",
       "  2.5  10.5   0.0   4.5   2.5   1.0     0.0   0.5   0.0   4.5   5.5   1.5\n",
       " 16.0  13.5   2.5   1.0  36.0   0.0     0.0   6.5   3.0   0.5   1.0  12.5"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.Ndk_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.0.3",
   "language": "julia",
   "name": "julia-1.0"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.0.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
