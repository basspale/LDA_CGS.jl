{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using Pkg\n",
    "using HDF5\n",
    "using JSON\n",
    "using SpecialFunctions\n",
    "using JLD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = []\n",
    "texts = []\n",
    "\n",
    "open(\"./data/hep-ph.json\", \"r\") do f\n",
    "    i=1\n",
    "    for line in eachline(f)\n",
    "        jdict = JSON.parse(line)\n",
    "        words = split(jdict[\"summary\"],r\" | |\\.|\\,|\\n|\\$\")\n",
    "        push!(texts, words)\n",
    "        union!(vocab, collect(words))\n",
    "        i += 1\n",
    "    end\n",
    "end\n",
    "\n",
    "vocab_size,  = size(vocab)\n",
    "word_to_id = Dict()\n",
    "id_to_word = Dict()\n",
    "for i in 1:vocab_size\n",
    "    word_to_id[vocab[i]] = i\n",
    "    id_to_word[i] = vocab[i]\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First make whole corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_size, = size(texts)\n",
    "corpus = []\n",
    "for text in texts\n",
    "    words_id = map(w->word_to_id[w], text)\n",
    "    \n",
    "    counts_d = Dict{Int, Int}()\n",
    "    for iv in words_id\n",
    "        counts_d[iv] = get(counts_d, iv, 0) + 1\n",
    "    end\n",
    "\n",
    "    counts_d_tuple = []\n",
    "    for (key, ct) in counts_d\n",
    "        push!(counts_d_tuple, (key, ct))\n",
    "    end\n",
    "    push!(corpus, counts_d_tuple)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then devide it into corpus for training and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# devide test and train\n",
    "train_ratio = 0.8\n",
    "train_corpus = []\n",
    "test_corpus = []\n",
    "\n",
    "for d in corpus\n",
    "    Nd, = size(d)\n",
    "    length = Int(round(Nd*0.8))\n",
    "    push!(train_corpus, d[1:length])\n",
    "    push!(test_corpus, d[length+1:end])\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Main.LDA_CGS"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "include(\"../src/LDA_CGS.jl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First make LDA object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Main.LDA_CGS.LDA(20, 13182, 1609732, #undef, #undef, #undef, #undef, #undef, #undef, 5.0e-324, 2.252070422e-314, 5.0e-323, #undef, 4558241281, 6.0e-323, #undef, #undef, #undef)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K = 20\n",
    "V = vocab_size\n",
    "x = LDA_CGS.LDA(K, V)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Burn-in (period=10)...\n",
      "epoch=1\n",
      "epoch=2\n",
      "epoch=3\n",
      "epoch=4\n",
      "epoch=5\n",
      "epoch=6\n",
      "epoch=7\n",
      "epoch=8\n",
      "epoch=9\n",
      "epoch=10\n",
      "Sample from the posterior...\n",
      "epoch=1, PPL=46.027711925313994\n",
      "epoch=2, PPL=45.37632130193404\n"
     ]
    }
   ],
   "source": [
    "burnin = 10\n",
    "sample = 2\n",
    "LDA_CGS.run(x, train_corpus, test_corpus, burnin, sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.0.0",
   "language": "julia",
   "name": "julia-1.0"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
